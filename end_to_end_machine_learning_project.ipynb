{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayinc/Machine-Learning_IIT/blob/main/end_to_end_machine_learning_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8mh2h6-uHYh"
      },
      "source": [
        "**End-to-end Machine Learning project**\n",
        "\n",
        "*Welcome to Machine Learning Housing Corp.! Your task is to predict median house values in Californian districts, given a number of features from these districts.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdZToEKuHYi"
      },
      "source": [
        "This notebook is inspired from the handson-ml2 GitHub repository by Aurélien Geron\n",
        "\n",
        "https://github.com/ageron/handson-ml2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWvnDJZLuHYj"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0nBNw95uHYj"
      },
      "source": [
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/sample_data\n"
      ],
      "metadata": {
        "id": "aOdItgj4DXCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RAPIDS cuDF is a GPU DataFrame library that accelerates the data processing tool pandas\n",
        "# Initiating cuDF to accelerate pandas code on your GPU-enabled Colab notebook:\n",
        "\n",
        "%load_ext cudf.pandas"
      ],
      "metadata": {
        "id": "V3AyNX6dXCkg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Define paths to datasets and images folders from Google Drive (for persistent storage)\n",
        "# Replace 'your_drive_folder' with the actual folder name in your Google Drive\n",
        "# sample_datasets_path = '/content/drive/My Drive/your_drive_folder/datasets'\n",
        "# sample_images_path = '/content/drive/My Drive/your_drive_folder/images'\n",
        "\n",
        "datasets_path = '/content/drive/MyDrive/00 Learning 2024/IIT-r/allfiles/datasets'\n",
        "images_path = '/content/drive/MyDrive/00 Learning 2024/IIT-r/allfiles/images'\n",
        "\n",
        "# Example of listing files in the datasets folder\n",
        "print(\"Datasets folder contents:\", os.listdir(datasets_path))\n",
        "print(\"Images folder contents:\", os.listdir(images_path))"
      ],
      "metadata": {
        "id": "tCeXsBuuDhFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32053dfc-51a8-4fae-bb6d-b170d5d8cbf5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Datasets folder contents: ['housing', 'kmeans']\n",
            "Images folder contents: ['cnn', 'end_to_end_project']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PTTN7I5uHYj"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"end_to_end_project\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "# Ignore useless warnings (see SciPy issue #5998)\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
        "\n",
        "# Check the directories and paths to ensure they are correctly set\n",
        "print(\"Project root directory contents:\", os.listdir(PROJECT_ROOT_DIR))\n",
        "print(\"Images path contents after creation:\", os.listdir(IMAGES_PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GuwSn9yuHYk"
      },
      "source": [
        "# Get the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBKRsFhSuHYk"
      },
      "outputs": [],
      "source": [
        "# Dataset is located at datasets/housing directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R4az46LuHYk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the path to the housing dataset\n",
        "HOUSING_PATH = os.path.join(datasets_path, \"housing\")\n",
        "\n",
        "# Function to load the housing dataset from a CSV file\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "housing = load_housing_data()\n",
        "housing.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPokD8v1uHYk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "housing = pd.read_csv('/content/drive/MyDrive/00 Learning 2024/IIT-r/allfiles/datasets/housing/housing.csv')\n",
        "housing.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JMaabILuHYl"
      },
      "outputs": [],
      "source": [
        "housing.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuvWr_AZuHYl"
      },
      "outputs": [],
      "source": [
        "housing[\"ocean_proximity\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMUY3mnSuHYl"
      },
      "outputs": [],
      "source": [
        "housing.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzwHOz-PuHYl"
      },
      "outputs": [],
      "source": [
        "#%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "housing.hist(bins=50, figsize=(20,15))\n",
        "save_fig(\"attribute_histogram_plots\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuWJzMlxuHYm"
      },
      "outputs": [],
      "source": [
        "# to make this notebook's output identical at every run\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "#np.random.random()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnJjIDWRuHYm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# For illustration only. Sklearn has train_test_split()\n",
        "def split_train_test(data, test_ratio):\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices], data.iloc[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ_paKQauHYm"
      },
      "outputs": [],
      "source": [
        "train_set, test_set = split_train_test(housing, 0.2)\n",
        "len(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu80ISTPuHYm"
      },
      "outputs": [],
      "source": [
        "len(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hkXZARnuHYm"
      },
      "outputs": [],
      "source": [
        "from zlib import crc32\n",
        "\n",
        "def test_set_check(identifier, test_ratio):\n",
        "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
        "\n",
        "def split_train_test_by_id(data, test_ratio, id_column):\n",
        "    ids = data[id_column]\n",
        "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
        "    return data.loc[~in_test_set], data.loc[in_test_set]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XZSyxi3uHYn"
      },
      "source": [
        "The implementation of `test_set_check()` above works fine in both Python 2 and Python 3. In earlier releases, the following implementation was proposed, which supported any hash function, but was much slower and did not support Python 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1BP2XymuHYn"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "\n",
        "def test_set_check(identifier, test_ratio, hash=hashlib.md5):\n",
        "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAuz7ZgYuHYn"
      },
      "source": [
        "If you want an implementation that supports any hash function and is compatible with both Python 2 and Python 3, here is one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTKOkMDzuHYn"
      },
      "outputs": [],
      "source": [
        "def test_set_check(identifier, test_ratio, hash=hashlib.md5):\n",
        "    return bytearray(hash(np.int64(identifier)).digest())[-1] < 256 * test_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajsOc6SfuHYn"
      },
      "outputs": [],
      "source": [
        "housing_with_id = housing.reset_index()   # adds an `index` column\n",
        "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bO_piNvuHYn"
      },
      "outputs": [],
      "source": [
        "housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
        "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WumwTS_uHYn"
      },
      "outputs": [],
      "source": [
        "test_set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP1tjRBVuHYn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sleq-4IluHYn"
      },
      "outputs": [],
      "source": [
        "test_set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f910dDKuHYn"
      },
      "outputs": [],
      "source": [
        "housing[\"median_income\"].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bygP7bSIuHYo"
      },
      "outputs": [],
      "source": [
        "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
        "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "                               labels=[1, 2, 3, 4, 5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUxOJyKmuHYo"
      },
      "outputs": [],
      "source": [
        "housing[\"income_cat\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2hDw6NKuHYo"
      },
      "outputs": [],
      "source": [
        "housing[\"income_cat\"].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql2VgayIuHYo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdhwk8UtuHYo"
      },
      "outputs": [],
      "source": [
        "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FY9vr9FuHYo"
      },
      "outputs": [],
      "source": [
        "housing[\"income_cat\"].value_counts() / len(housing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v68IBQbUuHYo"
      },
      "outputs": [],
      "source": [
        "def income_cat_proportions(data):\n",
        "    return data[\"income_cat\"].value_counts() / len(data)\n",
        "\n",
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
        "\n",
        "compare_props = pd.DataFrame({\n",
        "    \"Overall\": income_cat_proportions(housing),\n",
        "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
        "    \"Random\": income_cat_proportions(test_set),\n",
        "}).sort_index()\n",
        "compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\n",
        "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzLao15luHYo"
      },
      "outputs": [],
      "source": [
        "compare_props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsOdhabGuHYo"
      },
      "outputs": [],
      "source": [
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h79Mv8OWuHYp"
      },
      "source": [
        "# Discover and visualize the data to gain insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGR9RJ4iuHYp"
      },
      "outputs": [],
      "source": [
        "housing = strat_train_set.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObbV1paYuHYp"
      },
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\n",
        "save_fig(\"bad_visualization_plot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOls8_HNuHYp"
      },
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)\n",
        "save_fig(\"better_visualization_plot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "913_b7huuHYp"
      },
      "source": [
        "The argument `sharex=False` fixes a display bug (the x-axis values and legend were not displayed). This is a temporary fix (see: https://github.com/pandas-dev/pandas/issues/10611 ). Thanks to Wilmer Arellano for pointing it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X7sryBIuHYp"
      },
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
        "    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
        "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
        "    sharex=False)\n",
        "plt.legend()\n",
        "save_fig(\"housing_prices_scatterplot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xq3qZBq5uHYp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.image as mpimg\n",
        "california_img=mpimg.imread(\"extra_images/california.png\")\n",
        "ax = housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", figsize=(10,7),\n",
        "                       s=housing['population']/100, label=\"Population\",\n",
        "                       c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"),\n",
        "                       colorbar=False, alpha=0.4,\n",
        "                      )\n",
        "plt.imshow(california_img, extent=[-124.55, -113.80, 32.45, 42.05], alpha=0.5,\n",
        "           cmap=plt.get_cmap(\"jet\"))\n",
        "plt.ylabel(\"Latitude\", fontsize=14)\n",
        "plt.xlabel(\"Longitude\", fontsize=14)\n",
        "\n",
        "prices = housing[\"median_house_value\"]\n",
        "tick_values = np.linspace(prices.min(), prices.max(), 11)\n",
        "cbar = plt.colorbar()\n",
        "cbar.ax.set_yticklabels([\"$%dk\"%(round(v/1000)) for v in tick_values], fontsize=14)\n",
        "cbar.set_label('Median House Value', fontsize=16)\n",
        "\n",
        "plt.legend(fontsize=16)\n",
        "save_fig(\"california_housing_prices_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqVN5UrSuHYq"
      },
      "outputs": [],
      "source": [
        "corr_matrix = housing.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bz7SShc2uHYq"
      },
      "outputs": [],
      "source": [
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9raIHEzuHYq"
      },
      "outputs": [],
      "source": [
        "# from pandas.tools.plotting import scatter_matrix # For older versions of Pandas\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
        "              \"housing_median_age\"]\n",
        "scatter_matrix(housing[attributes], figsize=(12, 8))\n",
        "save_fig(\"scatter_matrix_plot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dp6UJmqVuHYq"
      },
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
        "             alpha=0.1)\n",
        "plt.axis([0, 16, 0, 550000])\n",
        "save_fig(\"income_vs_house_value_scatterplot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKWLYJPyuHYq"
      },
      "outputs": [],
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waVZ0rmDuHYq"
      },
      "outputs": [],
      "source": [
        "corr_matrix = housing.corr()\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaTtExujuHYq"
      },
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"rooms_per_household\", y=\"median_house_value\",\n",
        "             alpha=0.2)\n",
        "plt.axis([0, 5, 0, 520000])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL0W_c8uuHYq"
      },
      "outputs": [],
      "source": [
        "housing.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5-F1P-JuHYr"
      },
      "source": [
        "# Prepare the data for Machine Learning algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC07zAKCuHYr"
      },
      "outputs": [],
      "source": [
        "housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
        "housing_labels = strat_train_set[\"median_house_value\"].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcvnmzxpuHYr"
      },
      "outputs": [],
      "source": [
        "sample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\n",
        "sample_incomplete_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlC5El9vuHYr"
      },
      "outputs": [],
      "source": [
        "sample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])    # option 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zingvmhhuHYr"
      },
      "outputs": [],
      "source": [
        "sample_incomplete_rows.drop(\"total_bedrooms\", axis=1)       # option 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsUaBbE0uHYr"
      },
      "outputs": [],
      "source": [
        "median = housing[\"total_bedrooms\"].median()\n",
        "sample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True) # option 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuDmHRYAuHYs"
      },
      "outputs": [],
      "source": [
        "sample_incomplete_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bJHtdd9uHYs"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy=\"median\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBXTx3WuuHYs"
      },
      "source": [
        "Remove the text attribute because median can only be calculated on numerical attributes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp2jMJuTuHYs"
      },
      "outputs": [],
      "source": [
        "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
        "# alternatively: housing_num = housing.select_dtypes(include=[np.number])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHrwZNXOuHYs"
      },
      "outputs": [],
      "source": [
        "imputer.fit(housing_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p45pwkCGuHYs"
      },
      "outputs": [],
      "source": [
        "imputer.statistics_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcrsBRLquHYt"
      },
      "source": [
        "Check that this is the same as manually computing the median of each attribute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPKktIRauHYt"
      },
      "outputs": [],
      "source": [
        "housing_num.median().values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNflm6SHuHYt"
      },
      "source": [
        "Transform the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sta3YmtnuHYt"
      },
      "outputs": [],
      "source": [
        "X = imputer.transform(housing_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ISysPRjuHYt"
      },
      "outputs": [],
      "source": [
        "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
        "                          index=housing.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCQps9kZuHYu"
      },
      "outputs": [],
      "source": [
        "housing_tr.loc[sample_incomplete_rows.index.values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm4qi_6uuHYu"
      },
      "outputs": [],
      "source": [
        "imputer.strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO48j9uruHYu"
      },
      "outputs": [],
      "source": [
        "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
        "                          index=housing_num.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaCFQJoCuHYu"
      },
      "outputs": [],
      "source": [
        "housing_tr.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KkunTwXuHYu"
      },
      "source": [
        "Now let's preprocess the categorical input feature, `ocean_proximity`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aywT6xZZuHYu"
      },
      "outputs": [],
      "source": [
        "housing_cat = housing[[\"ocean_proximity\"]]\n",
        "housing_cat.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6FFuqvzuHYv"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
        "housing_cat_encoded[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D_-8GRZuHYv"
      },
      "outputs": [],
      "source": [
        "ordinal_encoder.categories_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGv0j9UruHYv"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_encoder = OneHotEncoder()\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "housing_cat_1hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5cokcR8uHYv"
      },
      "source": [
        "By default, the `OneHotEncoder` class returns a sparse array, but we can convert it to a dense array if needed by calling the `toarray()` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AVwtVEjuHYv"
      },
      "outputs": [],
      "source": [
        "housing_cat_1hot.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFP1gCJquHYw"
      },
      "source": [
        "Alternatively, you can set `sparse=False` when creating the `OneHotEncoder`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rXrdLv3uHYw"
      },
      "outputs": [],
      "source": [
        "cat_encoder = OneHotEncoder(sparse=False)\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "housing_cat_1hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAK4rMHVuHYw"
      },
      "outputs": [],
      "source": [
        "cat_encoder.categories_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM6lVy_6uHYw"
      },
      "source": [
        "Let's create a custom transformer to add extra attributes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiSRuTt5uHYw"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# column index\n",
        "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
        "\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
        "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "    def fit(self, X, y=None):\n",
        "        return self  # nothing else to do\n",
        "    def transform(self, X):\n",
        "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
        "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
        "        if self.add_bedrooms_per_room:\n",
        "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
        "            return np.c_[X, rooms_per_household, population_per_household,\n",
        "                         bedrooms_per_room]\n",
        "        else:\n",
        "            return np.c_[X, rooms_per_household, population_per_household]\n",
        "\n",
        "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
        "housing_extra_attribs = attr_adder.transform(housing.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HuA5v47uHYx"
      },
      "outputs": [],
      "source": [
        "housing_extra_attribs = pd.DataFrame(\n",
        "    housing_extra_attribs,\n",
        "    columns=list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"],\n",
        "    index=housing.index)\n",
        "housing_extra_attribs.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdVGnXaxuHYx"
      },
      "source": [
        "Now let's build a pipeline for preprocessing the numerical attributes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loL41tpluHYx"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('attribs_adder', CombinedAttributesAdder()),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "housing_num_tr = num_pipeline.fit_transform(housing_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WPSd3OruHYx"
      },
      "outputs": [],
      "source": [
        "housing_num_tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80-50wLzuHYx"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])\n",
        "\n",
        "housing_prepared = full_pipeline.fit_transform(housing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9bXKuWJuHYx"
      },
      "outputs": [],
      "source": [
        "housing_prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u49xJ05uHYx"
      },
      "outputs": [],
      "source": [
        "housing_prepared.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAtKIjwQuHYx"
      },
      "source": [
        "For reference, here is the old solution based on a `DataFrameSelector` transformer (to just select a subset of the Pandas `DataFrame` columns), and a `FeatureUnion`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTYMPsBkuHYx"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Create a class to select numerical or categorical columns\n",
        "class OldDataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, attribute_names):\n",
        "        self.attribute_names = attribute_names\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X[self.attribute_names].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPCDoOmLuHYy"
      },
      "source": [
        "Now let's join all these components into a big pipeline that will preprocess both the numerical and the categorical features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYCCVzBBuHYy"
      },
      "outputs": [],
      "source": [
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "old_num_pipeline = Pipeline([\n",
        "        ('selector', OldDataFrameSelector(num_attribs)),\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('attribs_adder', CombinedAttributesAdder()),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "old_cat_pipeline = Pipeline([\n",
        "        ('selector', OldDataFrameSelector(cat_attribs)),\n",
        "        ('cat_encoder', OneHotEncoder(sparse=False)),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAxHRMIUuHYy"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "old_full_pipeline = FeatureUnion(transformer_list=[\n",
        "        (\"num_pipeline\", old_num_pipeline),\n",
        "        (\"cat_pipeline\", old_cat_pipeline),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD9EftnMuHYy"
      },
      "outputs": [],
      "source": [
        "old_housing_prepared = old_full_pipeline.fit_transform(housing)\n",
        "old_housing_prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8HifXl7uHYy"
      },
      "source": [
        "The result is the same as with the `ColumnTransformer`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ5bVKkUuHYy"
      },
      "outputs": [],
      "source": [
        "np.allclose(housing_prepared, old_housing_prepared)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf7UnezEuHYy"
      },
      "source": [
        "# Select and train a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RZMKMzyuHYz"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6ssymhhuHYz"
      },
      "outputs": [],
      "source": [
        "# let's try the full preprocessing pipeline on a few training instances\n",
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "\n",
        "print(\"Predictions:\", lin_reg.predict(some_data_prepared))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bWwv_tQuHYz"
      },
      "source": [
        "Compare against the actual values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0018DONuHYz"
      },
      "outputs": [],
      "source": [
        "print(\"Labels:\", list(some_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "os5C9yUYuHYz"
      },
      "outputs": [],
      "source": [
        "some_data_prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oySRsVKruHYz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "lin_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiYcqCcOuHYz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "lin_mae = mean_absolute_error(housing_labels, housing_predictions)\n",
        "lin_mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI0-BJBAuHY0"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "tree_reg.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbWBNEbKuHY0"
      },
      "outputs": [],
      "source": [
        "housing_predictions = tree_reg.predict(housing_prepared)\n",
        "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "tree_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUcoLByLuHY0"
      },
      "source": [
        "# Fine-tune your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HvGh8d6uHY0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
        "tree_rmse_scores = np.sqrt(-scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBGgrj7GuHY0"
      },
      "outputs": [],
      "source": [
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())\n",
        "    print(\"Standard deviation:\", scores.std())\n",
        "\n",
        "display_scores(tree_rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP0s3MLKuHY0"
      },
      "outputs": [],
      "source": [
        "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiFzv9reuHY0"
      },
      "source": [
        "**Note**: we specify `n_estimators=100` to be future-proof since the default value is going to change to 100 in Scikit-Learn 0.22 (for simplicity, this is not shown in the book)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzNBPVVeuHY1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "forest_reg.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BPnC3RguHY1"
      },
      "outputs": [],
      "source": [
        "housing_predictions = forest_reg.predict(housing_prepared)\n",
        "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        "forest_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX3Kd5h1uHY1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
        "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
        "forest_rmse_scores = np.sqrt(-forest_scores)\n",
        "display_scores(forest_rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbQMUcaAuHY1"
      },
      "outputs": [],
      "source": [
        "scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
        "pd.Series(np.sqrt(-scores)).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NdERrv3uHY1"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "svm_reg = SVR(kernel=\"linear\")\n",
        "svm_reg.fit(housing_prepared, housing_labels)\n",
        "housing_predictions = svm_reg.predict(housing_prepared)\n",
        "svm_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "svm_rmse = np.sqrt(svm_mse)\n",
        "svm_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fn50LLtuHY1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "    # try 12 (3×4) combinations of hyperparameters\n",
        "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
        "    # then try 6 (2×3) combinations with bootstrap set as False\n",
        "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "  ]\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training\n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "grid_search.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4QINa-GuHY2"
      },
      "source": [
        "The best hyperparameter combination found:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa5IsKDhuHY2"
      },
      "outputs": [],
      "source": [
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M12jJs8wuHY2"
      },
      "outputs": [],
      "source": [
        "grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lMPT27iuHY2"
      },
      "source": [
        "Let's look at the score of each hyperparameter combination tested during the grid search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDKwfkNxuHY3"
      },
      "outputs": [],
      "source": [
        "cvres = grid_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oaype-pOuHY3"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(grid_search.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzZU0a_juHY3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_distribs = {\n",
        "        'n_estimators': randint(low=1, high=200),\n",
        "        'max_features': randint(low=1, high=8),\n",
        "    }\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
        "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
        "rnd_search.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_Eq70y9uHY3"
      },
      "outputs": [],
      "source": [
        "cvres = rnd_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7KkL-g9uHY3"
      },
      "outputs": [],
      "source": [
        "feature_importances = grid_search.best_estimator_.feature_importances_\n",
        "feature_importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzemGHG7uHY3"
      },
      "outputs": [],
      "source": [
        "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
        "#cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"] # old solution\n",
        "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
        "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
        "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
        "sorted(zip(feature_importances, attributes), reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggHwlvJhuHY3"
      },
      "outputs": [],
      "source": [
        "final_model = grid_search.best_estimator_\n",
        "\n",
        "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "final_predictions = final_model.predict(X_test_prepared)\n",
        "\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdupTw1vuHY4"
      },
      "outputs": [],
      "source": [
        "final_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1H6jf41uHY4"
      },
      "source": [
        "We can compute a 95% confidence interval for the test RMSE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNoxz_UauHY4"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "confidence = 0.95\n",
        "squared_errors = (final_predictions - y_test) ** 2\n",
        "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
        "                         loc=squared_errors.mean(),\n",
        "                         scale=stats.sem(squared_errors)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2Is84cAuHY4"
      },
      "source": [
        "We could compute the interval manually like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIK7NYdDuHY4"
      },
      "outputs": [],
      "source": [
        "m = len(squared_errors)\n",
        "mean = squared_errors.mean()\n",
        "tscore = stats.t.ppf((1 + confidence) / 2, df=m - 1)\n",
        "tmargin = tscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
        "np.sqrt(mean - tmargin), np.sqrt(mean + tmargin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbE3O1GDuHY4"
      },
      "source": [
        "Alternatively, we could use a z-scores rather than t-scores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtUZAHI2uHY4"
      },
      "outputs": [],
      "source": [
        "zscore = stats.norm.ppf((1 + confidence) / 2)\n",
        "zmargin = zscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
        "np.sqrt(mean - zmargin), np.sqrt(mean + zmargin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_zyRpgtuHY5"
      },
      "source": [
        "# Extra material"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijBiUv8ZuHY5"
      },
      "source": [
        "## A full pipeline with both preparation and prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4uFI_U5uHY5"
      },
      "outputs": [],
      "source": [
        "full_pipeline_with_predictor = Pipeline([\n",
        "        (\"preparation\", full_pipeline),\n",
        "        (\"linear\", LinearRegression())\n",
        "    ])\n",
        "\n",
        "full_pipeline_with_predictor.fit(housing, housing_labels)\n",
        "full_pipeline_with_predictor.predict(some_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjRdRrcquHY5"
      },
      "source": [
        "## Model persistence using joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggwRqBRUuHY5"
      },
      "outputs": [],
      "source": [
        "my_model = full_pipeline_with_predictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQulQdMXuHY5"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(my_model, \"my_model.pkl\") # DIFF\n",
        "#...\n",
        "my_model_loaded = joblib.load(\"my_model.pkl\") # DIFF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdtw79MZuHY6"
      },
      "source": [
        "## Example SciPy distributions for `RandomizedSearchCV`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBq_EpKuuHY6"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import geom, expon\n",
        "geom_distrib=geom(0.5).rvs(10000, random_state=42)\n",
        "expon_distrib=expon(scale=1).rvs(10000, random_state=42)\n",
        "plt.hist(geom_distrib, bins=50)\n",
        "plt.show()\n",
        "plt.hist(expon_distrib, bins=50)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "nav_menu": {
      "height": "279px",
      "width": "309px"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}